[model]
path = "C:\\Piper\\models\\Hermes-3-Llama-3.1-8B-Q5_K_M.gguf"
context_size = 12288 # was 16384
threads = 12
ngl = 0 # was 35
temperature = 0.8
top_k = 40
top_p = 0.95

[prompt]
template = "C:\\Piper\\config\\hermes3_chatml.jinja"
reply_reserve_tokens = 1000

[persona]
background_file = "C:\\Piper\\config\\persona_background.md"
traits_file     = "C:\\Piper\\config\\persona_traits.ini"

[memory]
mode = "running_only"    # hard requirement for BC01

[paths]
log_dir = "C:\\Piper\\logs"
prompt_log = "C:\\Piper\\logs\\rendered_prompt.log"

[features]
use_legacy_envs = false  # must stay false in BC01

[provider]
llamacpp_exe = "C:\\Piper\\llama.cpp\\llama-run"
